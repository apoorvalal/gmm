{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from gmm import GELEstimator\n",
    "np.random.seed(94305)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Empirical Likelihood Estimation\n",
    "\n",
    "We want to estimate a parameter implicitly defined as a solution to a moment condition $g(Z; \\theta) = 0$. \n",
    "\n",
    "GMM proceeds by minimizing the quadratic form $Q(\\theta) = g(Z; \\theta)'Wg(Z; \\theta)$, where $W$ is a positive definite weighting matrix. The choice of the weighting matrix is crucial for the efficiency of the estimator.\n",
    "\n",
    "GEL sidesteps the choice of the weighting matrix by minimizing the empirical likelihood function. The empirical likelihood function is defined as the maximum of the likelihood function subject to the moment condition.\n",
    "\n",
    "The (log) empirical likelihood function is defined as:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\max_{p \\in \\mathcal{P}} \\sum_{i=1}^n \\log p_i\n",
    "$$\n",
    "\n",
    "subject to the moment condition $$p_i g(Z; \\theta) = 0$$\n",
    "and adding up $\\sum_{i=1}^n p_i = 1$.\n",
    "\n",
    "where $\\mathcal{P}$ is the set of all probability distributions on $\\{1, \\ldots, n\\}$. At a first glance, this problem seems harder, since we need to solve for a weight vector $p$, which is typically of much higher dimension than the parameter $\\theta$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Imbens, Spady, and Johnson (1998)](https://scholar.harvard.edu/sites/scholar.harvard.edu/files/imbens/files/information_theoretic_approaches_to_inference_in_moment_condition_models.pdf) show that minimizing the KLIC instead of the log empirical likelihood produces better behavior under `mild' misspecification. The corresponding Exponential Tilting estimator is defined as solving\n",
    "\n",
    "$$\n",
    "\\max_{\\theta, p_i} - \\sum_{i=1}^n p_i \\log p_i\n",
    "$$\n",
    "\n",
    "subject to the moment condition $p_i g(Z; \\theta) = 0$ and $\\sum_{i=1}^n p_i = 1$. \n",
    "\n",
    "The estimating equations are difficult to solve directly, so we instead use the saddlepoint representation\n",
    "\n",
    "$$\n",
    "\\max_{\\theta} \\min_{t} \\sum_{i=1}^n \\exp(t' g(Z_i; \\theta))\n",
    "$$\n",
    "\n",
    "that concentrates out the weight vector.\n",
    "The inner function is strictly convex in $t$, and can be solved quickly. The outer function iterates over candidate values of $\\theta$. We implement this approach in `GELEstimator`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Problems\n",
    "\n",
    "### estimating a mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01999056, 0.03015686],\n",
       "       [2.04451165, 0.03196784]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "X = np.random.normal(np.array([1, 2]), size=(n, 2))\n",
    "np.c_[X.mean(axis=0), np.sqrt(n/(n-1) * X.var(axis=0)/n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01999054, 0.03015686],\n",
       "       [2.04451167, 0.03196784]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moment_cond_mean = lambda D, theta: D - theta\n",
    "\n",
    "gelmod = GELEstimator(m = moment_cond_mean)\n",
    "gelmod.fit(X, np.zeros(2))\n",
    "gelmod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gelmod\u001b[38;5;241m.\u001b[39m_inner_minimisation(torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m2.\u001b[39m]),\n\u001b[1;32m      2\u001b[0m                            torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      3\u001b[0m                            torch\u001b[38;5;241m.\u001b[39mtensor(X),)\n",
      "File \u001b[0;32m~/Desktop/code/gmm/gmm/gel.py:184\u001b[0m, in \u001b[0;36mGELEstimatorTorch._inner_minimisation\u001b[0;34m(self, lam, theta, D)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inner_minimisation\u001b[39m(\u001b[38;5;28mself\u001b[39m, lam, theta, D):\n\u001b[1;32m    183\u001b[0m     moments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm(D, theta)\n\u001b[0;32m--> 184\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrho(torch\u001b[38;5;241m.\u001b[39mmatmul(moments, lam)))\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj_value\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "gelmod._inner_minimisation(torch.tensor([1., 2.]),\n",
    "                           torch.zeros(2),\n",
    "                           torch.tensor(X),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m moment_cond_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m D, theta: D \u001b[38;5;241m-\u001b[39m theta\n\u001b[1;32m      3\u001b[0m gelmod \u001b[38;5;241m=\u001b[39m GELEstimator(m \u001b[38;5;241m=\u001b[39m moment_cond_mean, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m gelmod\u001b[38;5;241m.\u001b[39mfit(torch\u001b[38;5;241m.\u001b[39mtensor(X), torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      5\u001b[0m gelmod\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/Desktop/code/gmm/gmm/gel.py:162\u001b[0m, in \u001b[0;36mGELEstimatorTorch.fit\u001b[0;34m(self, D, startval, startval2)\u001b[0m\n\u001b[1;32m    160\u001b[0m     startval2 \u001b[38;5;241m=\u001b[39m startval\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Outer maximization\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m result \u001b[38;5;241m=\u001b[39m torchmin\u001b[38;5;241m.\u001b[39mminimize(  \u001b[38;5;66;03m# objective function has -1 in front\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m theta: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outer_maximization(theta, D, startval2),\n\u001b[1;32m    164\u001b[0m     startval,\n\u001b[1;32m    165\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_method,\n\u001b[1;32m    166\u001b[0m     options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m},\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# standard error\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mest \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m~/anaconda3/envs/metrics/lib/python3.11/site-packages/torchmin/minimize.py:91\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, method, max_iter, tol, options, callback, disp, return_all)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_bfgs(fun, x0, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_lbfgs(fun, x0, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_cg(fun, x0, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/anaconda3/envs/metrics/lib/python3.11/site-packages/torchmin/bfgs.py:381\u001b[0m, in \u001b[0;36m_minimize_lbfgs\u001b[0;34m(fun, x0, lr, history_size, max_iter, line_search, gtol, xtol, normp, callback, disp, return_all)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_minimize_lbfgs\u001b[39m(\n\u001b[1;32m    338\u001b[0m         fun, x0, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m, history_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    339\u001b[0m         line_search\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrong-wolfe\u001b[39m\u001b[38;5;124m'\u001b[39m, gtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, xtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-9\u001b[39m,\n\u001b[1;32m    340\u001b[0m         normp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, return_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    341\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize a multivariate function with L-BFGS\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m        Result of the optimization routine.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_bfgs_core(\n\u001b[1;32m    382\u001b[0m         fun, x0, lr, low_mem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, history_size\u001b[38;5;241m=\u001b[39mhistory_size,\n\u001b[1;32m    383\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39mmax_iter, line_search\u001b[38;5;241m=\u001b[39mline_search, gtol\u001b[38;5;241m=\u001b[39mgtol, xtol\u001b[38;5;241m=\u001b[39mxtol,\n\u001b[1;32m    384\u001b[0m         normp\u001b[38;5;241m=\u001b[39mnormp, callback\u001b[38;5;241m=\u001b[39mcallback, disp\u001b[38;5;241m=\u001b[39mdisp, return_all\u001b[38;5;241m=\u001b[39mreturn_all)\n",
      "File \u001b[0;32m~/anaconda3/envs/metrics/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/metrics/lib/python3.11/site-packages/torchmin/bfgs.py:169\u001b[0m, in \u001b[0;36m_minimize_bfgs_core\u001b[0;34m(fun, x0, lr, low_mem, history_size, inv_hess, max_iter, line_search, gtol, xtol, normp, callback, disp, return_all)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# compute initial f(x) and f'(x)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m x \u001b[38;5;241m=\u001b[39m x0\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\n\u001b[0;32m--> 169\u001b[0m f, g, _, _ \u001b[38;5;241m=\u001b[39m closure(x)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial fval: \u001b[39m\u001b[38;5;132;01m%0.4f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m f)\n",
      "File \u001b[0;32m~/anaconda3/envs/metrics/lib/python3.11/site-packages/torchmin/function.py:109\u001b[0m, in \u001b[0;36mScalarFunction.closure\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 109\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x)\n\u001b[1;32m    110\u001b[0m     grad \u001b[38;5;241m=\u001b[39m autograd\u001b[38;5;241m.\u001b[39mgrad(f, x, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hessp \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hess)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hessp \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hess) \u001b[38;5;129;01mand\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/metrics/lib/python3.11/site-packages/torchmin/function.py:93\u001b[0m, in \u001b[0;36mScalarFunction.fun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x_shape:\n\u001b[1;32m     92\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x_shape)\n\u001b[0;32m---> 93\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(x)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFunction was supplied a function \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     96\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthat does not return scalar outputs.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/code/gmm/gmm/gel.py:163\u001b[0m, in \u001b[0;36mGELEstimatorTorch.fit.<locals>.<lambda>\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m    160\u001b[0m     startval2 \u001b[38;5;241m=\u001b[39m startval\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Outer maximization\u001b[39;00m\n\u001b[1;32m    162\u001b[0m result \u001b[38;5;241m=\u001b[39m torchmin\u001b[38;5;241m.\u001b[39mminimize(  \u001b[38;5;66;03m# objective function has -1 in front\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m theta: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outer_maximization(theta, D, startval2),\n\u001b[1;32m    164\u001b[0m     startval,\n\u001b[1;32m    165\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_method,\n\u001b[1;32m    166\u001b[0m     options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m},\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# standard error\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mest \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m~/Desktop/code/gmm/gmm/gel.py:174\u001b[0m, in \u001b[0;36mGELEstimatorTorch._outer_maximization\u001b[0;34m(self, theta, D, startval2)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_outer_maximization\u001b[39m(\u001b[38;5;28mself\u001b[39m, theta, D, startval2):\n\u001b[0;32m--> 174\u001b[0m     result \u001b[38;5;241m=\u001b[39m torchmin\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_minimisation(x, theta, D),\n\u001b[1;32m    176\u001b[0m         startval2,\n\u001b[1;32m    177\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_method,\n\u001b[1;32m    178\u001b[0m         options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m},\n\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mresult\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/anaconda3/envs/metrics/lib/python3.11/site-packages/torchmin/minimize.py:91\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, method, max_iter, tol, options, callback, disp, return_all)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_bfgs(fun, x0, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_lbfgs(fun, x0, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_cg(fun, x0, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/anaconda3/envs/metrics/lib/python3.11/site-packages/torchmin/bfgs.py:381\u001b[0m, in \u001b[0;36m_minimize_lbfgs\u001b[0;34m(fun, x0, lr, history_size, max_iter, line_search, gtol, xtol, normp, callback, disp, return_all)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_minimize_lbfgs\u001b[39m(\n\u001b[1;32m    338\u001b[0m         fun, x0, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m, history_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    339\u001b[0m         line_search\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrong-wolfe\u001b[39m\u001b[38;5;124m'\u001b[39m, gtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, xtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-9\u001b[39m,\n\u001b[1;32m    340\u001b[0m         normp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, return_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    341\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize a multivariate function with L-BFGS\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m        Result of the optimization routine.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_bfgs_core(\n\u001b[1;32m    382\u001b[0m         fun, x0, lr, low_mem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, history_size\u001b[38;5;241m=\u001b[39mhistory_size,\n\u001b[1;32m    383\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39mmax_iter, line_search\u001b[38;5;241m=\u001b[39mline_search, gtol\u001b[38;5;241m=\u001b[39mgtol, xtol\u001b[38;5;241m=\u001b[39mxtol,\n\u001b[1;32m    384\u001b[0m         normp\u001b[38;5;241m=\u001b[39mnormp, callback\u001b[38;5;241m=\u001b[39mcallback, disp\u001b[38;5;241m=\u001b[39mdisp, return_all\u001b[38;5;241m=\u001b[39mreturn_all)\n",
      "File \u001b[0;32m~/anaconda3/envs/metrics/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/metrics/lib/python3.11/site-packages/torchmin/bfgs.py:169\u001b[0m, in \u001b[0;36m_minimize_bfgs_core\u001b[0;34m(fun, x0, lr, low_mem, history_size, inv_hess, max_iter, line_search, gtol, xtol, normp, callback, disp, return_all)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# compute initial f(x) and f'(x)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m x \u001b[38;5;241m=\u001b[39m x0\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\n\u001b[0;32m--> 169\u001b[0m f, g, _, _ \u001b[38;5;241m=\u001b[39m closure(x)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial fval: \u001b[39m\u001b[38;5;132;01m%0.4f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m f)\n",
      "File \u001b[0;32m~/anaconda3/envs/metrics/lib/python3.11/site-packages/torchmin/function.py:109\u001b[0m, in \u001b[0;36mScalarFunction.closure\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 109\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x)\n\u001b[1;32m    110\u001b[0m     grad \u001b[38;5;241m=\u001b[39m autograd\u001b[38;5;241m.\u001b[39mgrad(f, x, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hessp \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hess)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hessp \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hess) \u001b[38;5;129;01mand\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/metrics/lib/python3.11/site-packages/torchmin/function.py:93\u001b[0m, in \u001b[0;36mScalarFunction.fun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x_shape:\n\u001b[1;32m     92\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x_shape)\n\u001b[0;32m---> 93\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(x)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFunction was supplied a function \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     96\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthat does not return scalar outputs.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/code/gmm/gmm/gel.py:175\u001b[0m, in \u001b[0;36mGELEstimatorTorch._outer_maximization.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_outer_maximization\u001b[39m(\u001b[38;5;28mself\u001b[39m, theta, D, startval2):\n\u001b[1;32m    174\u001b[0m     result \u001b[38;5;241m=\u001b[39m torchmin\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[0;32m--> 175\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_minimisation(x, theta, D),\n\u001b[1;32m    176\u001b[0m         startval2,\n\u001b[1;32m    177\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_method,\n\u001b[1;32m    178\u001b[0m         options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m},\n\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mresult\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/Desktop/code/gmm/gmm/gel.py:184\u001b[0m, in \u001b[0;36mGELEstimatorTorch._inner_minimisation\u001b[0;34m(self, lam, theta, D)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inner_minimisation\u001b[39m(\u001b[38;5;28mself\u001b[39m, lam, theta, D):\n\u001b[1;32m    183\u001b[0m     moments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm(D, theta)\n\u001b[0;32m--> 184\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrho(torch\u001b[38;5;241m.\u001b[39mmatmul(moments, lam)))\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj_value\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "moment_cond_mean = lambda D, theta: D - theta\n",
    "\n",
    "gelmod = GELEstimator(m = moment_cond_mean, backend=\"torch\")\n",
    "gelmod.fit(torch.tensor(X), torch.zeros(2))\n",
    "gelmod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytic and GEL estimates identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgp(n=100_000, beta=np.array([-0.5, 1.2]), rho=0.7, pi=np.array([0.5, -0.1])):\n",
    "    ε = np.random.normal(0, 1, n)\n",
    "    z = np.random.normal(0, 1, n * pi.shape[0]).reshape(n, pi.shape[0])\n",
    "    # Generate endogenous x, influenced by the instrument\n",
    "    x = z @ pi + ε * rho + np.random.normal(0, 1, n)\n",
    "    X = np.c_[np.ones(n), x]\n",
    "    # heteroskedasticity\n",
    "    y = X @ beta + ε + np.random.normal(0, 1 + 2 * (X[:, 1] > 0) + 1 * (np.abs(X[:, 1]) > 0.5), n)\n",
    "    return y, X, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.4980      0.010    -51.823      0.000      -0.517      -0.479\n",
      "x1             1.2048      0.009    130.295      0.000       1.187       1.223\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X, z = dgp(rho = 0)\n",
    "print(sm.OLS(y, X).fit(cov_type = \"HC2\").summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Estimation via EL/ET__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.49799059,  0.00961084],\n",
       "       [ 1.20481178,  0.01167324]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def moment_condition_ols(D, θ):\n",
    "    y, X = D[:, 0], D[:, 1:]\n",
    "    r = y - X @ θ\n",
    "    return X * r[:, None]\n",
    "\n",
    "D = np.c_[y, X]\n",
    "gelmod = GELEstimator(m = moment_condition_ols, verbose=False)\n",
    "k = X.shape[1]\n",
    "gelmod.fit(D, np.zeros(k))\n",
    "gelmod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.5031      0.010    -52.128      0.000      -0.522      -0.484\n",
      "x1             1.6453      0.007    241.302      0.000       1.632       1.659\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X, Z = dgp(rho = 1)\n",
    "print(sm.OLS(y, X).fit(cov_type = \"HC2\").summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2129555645196368, 0.01892188485776335)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2SLS via control function\n",
    "D = X[:, 1]\n",
    "Dhat = sm.OLS(D, Z).fit().predict()\n",
    "tslsreg = sm.OLS(y, np.c_[sm.add_constant(D), D - Dhat]).fit(cov_type=\"HC1\")\n",
    "tslsreg.params[1], tslsreg.bse[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unbiased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52258708, 0.01041044],\n",
       "       [1.22171316, 0.01039752]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def moment_condition_iv(D, θ):\n",
    "    y, X, Z = D[:, 0], D[:, 1:3], D[:, 3:]\n",
    "    r = y - X @ θ\n",
    "    return Z * r[:, None]\n",
    "\n",
    "\n",
    "D = np.c_[y, X, Z]\n",
    "k = X.shape[1]\n",
    "gelmod = GELEstimator(m=moment_condition_iv)\n",
    "gelmod.fit(D, np.zeros(k))\n",
    "gelmod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Endogenous coefficient is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Problems \n",
    "\n",
    "### Lin Regression\n",
    "\n",
    "$$\n",
    "Y_i = \\alpha + \\tau Z_i + X_i' \\beta + Z_i \\tilde{X}_i' \\gamma + \\epsilon_i\n",
    "$$\n",
    "\n",
    "where $\\tilde{X}_i = X_i - \\bar{X}$ is the centered version of $X_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "X = np.random.normal(0, 1, n * 2).reshape(n, 2)\n",
    "Y0 = X[:, 0] + X[:, 0] ** 2 + np.random.uniform(-0.5, 0.5, n)\n",
    "Y1 = X[:, 1] + X[:, 1] ** 2 + np.random.uniform(-1, 1, n)\n",
    "Z = np.random.binomial(1, 0.6, n)\n",
    "Y = Y0 * (1 - Z) + Y1 * Z\n",
    "D = np.c_[Y, Z, X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.0189</td> <td>    0.098</td> <td>   10.413</td> <td> 0.000</td> <td>    0.827</td> <td>    1.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.1907</td> <td>    0.139</td> <td>    1.371</td> <td> 0.170</td> <td>   -0.082</td> <td>    0.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.9860</td> <td>    0.191</td> <td>    5.167</td> <td> 0.000</td> <td>    0.612</td> <td>    1.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.1129</td> <td>    0.101</td> <td>    1.114</td> <td> 0.265</td> <td>   -0.086</td> <td>    0.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.8281</td> <td>    0.218</td> <td>   -3.794</td> <td> 0.000</td> <td>   -1.256</td> <td>   -0.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    1.4133</td> <td>    0.213</td> <td>    6.633</td> <td> 0.000</td> <td>    0.996</td> <td>    1.831</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lcccccc}\n",
       "\\toprule\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       1.0189  &        0.098     &    10.413  &         0.000        &        0.827    &        1.211     \\\\\n",
       "\\textbf{x1}    &       0.1907  &        0.139     &     1.371  &         0.170        &       -0.082    &        0.463     \\\\\n",
       "\\textbf{x2}    &       0.9860  &        0.191     &     5.167  &         0.000        &        0.612    &        1.360     \\\\\n",
       "\\textbf{x3}    &       0.1129  &        0.101     &     1.114  &         0.265        &       -0.086    &        0.311     \\\\\n",
       "\\textbf{x4}    &      -0.8281  &        0.218     &    -3.794  &         0.000        &       -1.256    &       -0.400     \\\\\n",
       "\\textbf{x5}    &       1.4133  &        0.213     &     6.633  &         0.000        &        0.996    &        1.831     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olslin = sm.OLS(\n",
    "    Y, np.c_[sm.add_constant(Z), X, Z[:, None] * (X - X.mean(axis=0))]\n",
    ").fit(cov_type = \"HC2\")\n",
    "olslin.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point estimates are consistent, but we do not propagate forward the uncertainty from estimating the sample mean $\\bar{X}$. To do this, we could stack the moment conditions\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "X - \\mu \\\\\n",
    "[X, X - \\mu] (y - [X, X - \\mu] \\beta)\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02681823 0.0657933  0.16969411 0.20839162 0.96615393 0.1186393\n",
      " 0.76986621 0.31422366]\n"
     ]
    }
   ],
   "source": [
    "def moment_condition_lin(D, θ):\n",
    "    Y, Z, X = D[:, 0], D[:, 1], D[:, 2:]\n",
    "    n, p = X.shape\n",
    "    mu, beta = θ[:p], θ[p:]\n",
    "    Xcent = X - mu\n",
    "    XX = np.c_[np.ones(n), Z, X, Z[:, None] * Xcent]\n",
    "    r = XX * (Y - XX @ beta)[:, None]\n",
    "    return np.c_[Xcent, r]\n",
    "print(theta_init := np.r_[X.mean(axis=0), np.random.rand(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gelmod = GELEstimator(m=moment_condition_lin, min_method=\"COBYLA\")\n",
    "gelmod.fit(D, theta_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02047514,  0.04419224,  0.02681823],\n",
       "       [ 0.067958  ,  0.04785572,  0.0657933 ],\n",
       "       [ 1.01598886,  0.07163751,  1.01894042],\n",
       "       [ 0.20515589,  0.06153608,  0.1907456 ],\n",
       "       [ 0.91805187,  0.0943588 ,  0.98603771],\n",
       "       [ 0.11959629,  0.14415267,  0.1128657 ],\n",
       "       [-0.74880967,  0.0628265 , -0.82811793],\n",
       "       [ 1.42066068,  0.13805289,  1.41325515]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[gelmod.summary(), np.r_[X.mean(axis = 0), olslin.params]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This parameter vector has $\\bar{X}$ as the first two elements, and the later are the regression coefficients. These look about right, although the standard errors are a bit too narrow?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
